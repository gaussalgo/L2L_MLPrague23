{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to In-context learning\n",
    "1. **🤖 What is in-context learning (ICL)**\n",
    "2. **🦮 Zero-shot vs. Few-shot ICL**\n",
    "3. **🎨 Prompt design**\n",
    "4. **✋ Hands-on: Transforming a dataset into a few-shot prompt-label dataset and evaluating existing models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fewshot-goes-multilingual/promptsource\n",
      "  Cloning https://github.com/fewshot-goes-multilingual/promptsource to /tmp/pip-req-build-9supn9vs\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fewshot-goes-multilingual/promptsource /tmp/pip-req-build-9supn9vs\n",
      "  Resolved https://github.com/fewshot-goes-multilingual/promptsource to commit eb6d175b2c397cb7ee2aa46c334c17e3238a49cc\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: black<=21.12b0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (21.12b0)\n",
      "Requirement already satisfied: datasets>=1.7.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (2.12.0)\n",
      "Requirement already satisfied: flake8 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (6.0.0)\n",
      "Requirement already satisfied: isort==5.8.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (5.8.0)\n",
      "Requirement already satisfied: jinja2 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (3.1.2)\n",
      "Requirement already satisfied: pandas in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (2.0.1)\n",
      "Requirement already satisfied: plotly in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (5.14.1)\n",
      "Requirement already satisfied: py7zr in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (0.20.5)\n",
      "Requirement already satisfied: pytest in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (7.3.1)\n",
      "Requirement already satisfied: pyyaml>=5 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (6.0)\n",
      "Requirement already satisfied: requests in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (2.30.0)\n",
      "Requirement already satisfied: streamlit==0.82 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from promptsource==0.2.3) (0.82.0)\n",
      "Requirement already satisfied: altair>=3.2.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (5.0.0)\n",
      "Requirement already satisfied: astor in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (0.8.1)\n",
      "Requirement already satisfied: base58 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (2.1.1)\n",
      "Requirement already satisfied: blinker in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (1.6.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (5.3.0)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (7.1.2)\n",
      "Requirement already satisfied: numpy in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (9.5.0)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (4.23.1)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (0.8.1b0)\n",
      "Requirement already satisfied: python-dateutil in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: toml in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (6.3.2)\n",
      "Requirement already satisfied: tzlocal in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (5.0.1)\n",
      "Requirement already satisfied: validators in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (0.20.0)\n",
      "Requirement already satisfied: gitpython in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (3.1.31)\n",
      "Requirement already satisfied: watchdog in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from streamlit==0.82->promptsource==0.2.3) (3.0.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from black<=21.12b0->promptsource==0.2.3) (3.5.1)\n",
      "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from black<=21.12b0->promptsource==0.2.3) (1.2.3)\n",
      "Requirement already satisfied: pathspec<1,>=0.9.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from black<=21.12b0->promptsource==0.2.3) (0.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from black<=21.12b0->promptsource==0.2.3) (4.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from black<=21.12b0->promptsource==0.2.3) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (0.14.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from datasets>=1.7.0->promptsource==0.2.3) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from pandas->promptsource==0.2.3) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from pandas->promptsource==0.2.3) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from requests->promptsource==0.2.3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from requests->promptsource==0.2.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from requests->promptsource==0.2.3) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from requests->promptsource==0.2.3) (2023.5.7)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from flake8->promptsource==0.2.3) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from flake8->promptsource==0.2.3) (2.10.0)\n",
      "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from flake8->promptsource==0.2.3) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from jinja2->promptsource==0.2.3) (2.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from plotly->promptsource==0.2.3) (8.2.2)\n",
      "Requirement already satisfied: texttable in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (3.18.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (0.15.7)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (1.0.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (0.3.1)\n",
      "Requirement already satisfied: psutil in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from py7zr->promptsource==0.2.3) (5.9.5)\n",
      "Requirement already satisfied: iniconfig in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from pytest->promptsource==0.2.3) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from pytest->promptsource==0.2.3) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from pytest->promptsource==0.2.3) (1.1.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==0.82->promptsource==0.2.3) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from altair>=3.2.0->streamlit==0.82->promptsource==0.2.3) (0.12.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from aiohttp->datasets>=1.7.0->promptsource==0.2.3) (1.3.1)\n",
      "Requirement already satisfied: filelock in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets>=1.7.0->promptsource==0.2.3) (3.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from python-dateutil->streamlit==0.82->promptsource==0.2.3) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from gitpython->streamlit==0.82->promptsource==0.2.3) (4.0.10)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from validators->streamlit==0.82->promptsource==0.2.3) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython->streamlit==0.82->promptsource==0.2.3) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.82->promptsource==0.2.3) (0.19.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/fewshot-goes-multilingual/promptsource"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 🤖 In-context learning (ICL)\n",
    "\n",
    "In context learning is a use of a generative model, where the description of a desired task is a part of the input. \n",
    "\n",
    "While pre-training, the model is trained on an objective of \"guessing\" the right word in context. This is achieved by objectives like Masked Language Modeling (MLM) or Causal Language Modeling (CLM). During these objectives, the model aquires an inherent understanding of the language. \n",
    "\n",
    "After pre-training, traditionaly, we would then fine-tune the model through Supervised ML for a specific task for which we need:\n",
    "* Training data (input and label pairs)\n",
    "* Adding a specific layer (\"head\") to the model relevant to our desired task\n",
    "The resulting model is fit for that one specific task.\n",
    "\n",
    "When we talk about In-context learning, we mean a property of a model to solve tasks it was not fine-tuned for with only instructions provided in the user's input, aka a prompt. In-context learning is a property usually seen in Large Language Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    " \n",
    "model_path = \"gaussalgo/mt5-base-priming-QA_en-cs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The plot is centered around a young Swedish drama student named Lena']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is meant by: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. \n",
    "I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\"\n",
    "I really had to see this for myself. The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life.\n",
    "In particular she wants to focus her attentions to making some sort of documentary on what the\n",
    "average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. \n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs.to(model.device))\n",
    "outputs_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# predictions:\n",
    "outputs_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 🦮 Zero-shot vs few-shot in-context learning\n",
    "The model might understand the task from the input, but it does not know how do we expect it to respond. Therefore, if we have the model adjusted for such use, we can show it the format of the task from a few input-output examples and see if it comprehends.\n",
    "\n",
    "This approach is called in-context few-shot learning: In addition to the description of the task, we give the model a few input-output examples (demonstrations). Given these, the model has much easier time understanding the format of the interaction that we expect from it. The demonstration are the only lead the model has to understand the task at hand. We can see, that if we pick only examples with a negative sentiment, the model is unable to pick the correct label. \n",
    "\n",
    "In this setting, we need to standardize the format of prediction, so that the model can rely on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'positive or negative', 'positive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_zero_shot = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "input_few_shot_not_heterogenic = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: He said, that the consert was very dull.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: She came from school sad and lonely.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "input_few_shot = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: He said, that the consert was very dull.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: She came from school smiling and singing.\n",
    "Answer:\"positive\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "inputs = tokenizer([input_zero_shot,input_few_shot_not_heterogenic,  input_few_shot], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs.to(model.device))\n",
    "outputs_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# predictions:\n",
    "outputs_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 🎨 What should the prompts look like?\n",
    "For training a custom in-context learner we need text pairs of a prompt and label. While in the above example we see a unified prompt, in training it is beneficial to create multiple prompts for one task, as we want to support the models capability to understand the task by its description, not by identifying a task by a template. This diversivication should yield a benefit of having the model understanding never before seen tasks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO write your own prompt (format string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset super_glue (/home/nikola/.cache/huggingface/datasets/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-3 Style', 'I wonder…', 'after_reading', 'based on the following passage', 'based on the previous passage', 'could you tell me…', 'exam', 'exercise', 'valid_binary', 'yes_no_question']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from promptsource.templates import DatasetTemplates\n",
    "\n",
    "dataset = load_dataset('super_glue', 'boolq', split=\"validation[:10%]\")\n",
    "\n",
    "prompts = DatasetTemplates(\"super_glue/boolq\")\n",
    "print(prompts.all_template_names)\n",
    "prompt = prompts['GPT-3 Style']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation\n",
    "Let's evaluate our model on a dataset created using the promptsource library and a dataset about if the answer to a question is in the context. (The model was not trained on this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Ethanol fuel -- All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\\nQuestion: does ethanol take more energy make that produces?\", 'No']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/327 [00:00<05:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Property tax -- Property tax or 'house tax' is a local tax on buildings, along with appurtenant land. It is and imposed on the Possessor (not the custodian of property as per 1978, 44th amendment of constitution). It resembles the US-type wealth tax and differs from the excise-type UK rate. The tax power is vested in the states and is delegated to local bodies, specifying the valuation method, rate band, and collection procedures. The tax base is the annual rental value (ARV) or area-based rating. Owner-occupied and other properties not producing rent are assessed on cost and then converted into ARV by applying a percentage of cost, usually four percent. Vacant land is generally exempt. Central government properties are exempt. Instead a 'service charge' is permissible under executive order. Properties of foreign missions also enjoy tax exemption without requiring reciprocity. The tax is usually accompanied by service taxes, e.g., water tax, drainage tax, conservancy (sanitation) tax, lighting tax, all using the same tax base. The rate structure is flat on rural (panchayat) properties, but in the urban (municipal) areas it is mildly progressive with about 80% of assessments falling in the first two brackets.\\nQuestion: is house tax and property tax are same?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/327 [00:02<06:26,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: Phantom pain -- Phantom pain sensations are described as perceptions that an individual experiences relating to a limb or an organ that is not physically part of the body. Limb loss is a result of either removal by amputation or congenital limb deficiency. However, phantom limb sensations can also occur following nerve avulsion or spinal cord injury.\\nQuestion: is pain experienced in a missing body part or paralyzed area?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/327 [00:03<06:16,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: Harry Potter and the Escape from Gringotts -- Harry Potter and the Escape from Gringotts is an indoor steel roller coaster at Universal Studios Florida, a theme park located within the Universal Orlando Resort. Similar to dark rides, the roller coaster utilizes special effects in a controlled-lighting environment and also employs motion-based 3-D projection of both animation and live-action sequences to enhance the experience. The ride, which is themed to the Gringotts Wizarding Bank, became the flagship attraction for the expanded Wizarding World of Harry Potter when it opened on July 8, 2014.\\nQuestion: is harry potter and the escape from gringotts a roller coaster ride?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/327 [00:04<05:28,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Hydroxyzine -- Hydroxyzine preparations require a doctor's prescription. The drug is available in two formulations, the pamoate and the dihydrochloride or hydrochloride salts. Vistaril, Equipose, Masmoran, and Paxistil are preparations of the pamoate salt, while Atarax, Alamon, Aterax, Durrax, Tran-Q, Orgatrax, Quiess, and Tranquizine are of the hydrochloride salt.\\nQuestion: is there a difference between hydroxyzine hcl and hydroxyzine pam?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/327 [00:05<06:25,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Barq's -- Barq's /ˈbɑːrks/ is an American soft drink. Its brand of root beer is notable for having caffeine. Barq's, created by Edward Barq and bottled since the turn of the 20th century, is owned by the Barq family but bottled by the Coca-Cola Company. It was known as Barq's Famous Olde Tyme Root Beer until 2012.\\nQuestion: is barq's root beer a pepsi product?\", 'No']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/327 [00:06<05:20,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Parity (mathematics) -- In mathematics, parity is the property of an integer's inclusion in one of two categories: even or odd. An integer is even if it is evenly divisible by two and odd if it is not even. For example, 6 is even because there is no remainder when dividing it by 2. By contrast, 3, 5, 7, 21 leave a remainder of 1 when divided by 2. Examples of even numbers include −4, 0, 82 and 178. In particular, zero is an even number. Some examples of odd numbers are −5, 3, 29, and 73.\\nQuestion: can an odd number be divided by an even number?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/327 [00:07<05:37,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: List of English words containing Q not followed by U -- Of the 71 words in this list, 67 are nouns, and most would generally be considered loanwords; the only modern-English words that contain Q not followed by U and are not borrowed from another language are qiana, qwerty, and tranq. However, all of the loanwords on this list are considered to be naturalised in English according to at least one major dictionary (see References), often because they refer to concepts or societal roles that do not have an accurate equivalent in English. For words to appear here, they must appear in their own entry in a dictionary; words which occur only as part of a longer phrase are not included.\\nQuestion: is there a word with q without u?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/327 [00:08<05:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: American entry into Canada by land -- Persons driving into Canada must have their vehicle's registration document and proof of insurance.\\nQuestion: can u drive in canada with us license?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/327 [00:08<04:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: 2018 FIFA World Cup knockout stage -- The knockout stage of the 2018 FIFA World Cup was the second and final stage of the competition, following the group stage. It began on 30 June with the round of 16 and ended on 15 July with the final match, held at the Luzhniki Stadium in Moscow. The top two teams from each group (16 in total) advanced to the knockout stage to compete in a single-elimination style tournament. A third place play-off was also played between the two losing teams of the semi-finals.\\nQuestion: is there a play off for third place in the world cup?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/327 [00:09<04:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: Alcohol laws of New York -- In response to the National Minimum Drinking Age Act in 1984, which reduced by up to 10% the federal highway funding of any state which did not have a minimum purchasing age of 21, the New York Legislature raised the drinking age from 19 to 21, effective December 1, 1985. (The drinking age had been 18 for many years before the first raise on December 4th, 1982, to 19.) Persons under 21 are prohibited from purchasing alcohol or possessing alcohol with the intent to consume, unless the alcohol was given to that person by their parent or legal guardian. There is no law prohibiting where people under 21 may possess or consume alcohol that was given to them by their parents. Persons under 21 are prohibited from having a blood alcohol level of 0.02% or higher while driving.\\nQuestion: can minors drink with parents in new york?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/327 [00:10<03:48,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Bloodline (TV series) -- Bloodline was announced in October 2014 as part of a partnership between Netflix and Sony Pictures Television, representing Netflix's first major deal with a major film studio for a television series. The series was created and executive produced by Todd A. Kessler, Glenn Kessler, and Daniel Zelman, who previously created the FX series Damages. According to its official synopsis released by Netflix, Bloodline ``centers on a close-knit family of four adult siblings whose secrets and scars are revealed when their black sheep brother returns home.''\\nQuestion: is the show bloodline based on a true story?\", 'No']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 12/327 [00:10<03:39,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Shower gel -- Shower gels for men may contain the ingredient menthol, which gives a cooling and stimulating sensation on the skin, and some men's shower gels are also designed specifically for use on hair and body. Shower gels contain milder surfactant bases than shampoos, and some also contain gentle conditioning agents in the formula. This means that shower gels can also double as an effective and perfectly acceptable substitute to shampoo, even if they are not labelled as a hair and body wash. Washing hair with shower gel should give approximately the same result as using a moisturising shampoo.\\nQuestion: is it bad to wash your hair with shower gel?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/327 [00:11<04:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Excretory system -- The liver detoxifies and breaks down chemicals, poisons and other toxins that enter the body. For example, the liver transforms ammonia (which is poisonous) into urea in fish, amphibians and mammals, and into uric acid in birds and reptiles. Urea is filtered by the kidney into urine or through the gills in fish and tadpoles. Uric acid is paste-like and expelled as a semi-solid waste (the ``white'' in bird excrements). The liver also produces bile, and the body uses bile to break down fats into usable fats and unusable waste.\\nQuestion: is the liver part of the excretory system?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/327 [00:12<04:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: Fantastic Beasts and Where to Find Them (film) -- Fantastic Beasts and Where to Find Them is a 2016 fantasy film directed by David Yates. A joint British and American production, it is a spin-off and prequel to the Harry Potter film series, and it was produced and written by J.K. Rowling in her screenwriting debut, and inspired by her 2001 book of the same name. The film stars Eddie Redmayne as Newt Scamander, with Katherine Waterston, Dan Fogler, Alison Sudol, Ezra Miller, Samantha Morton, Jon Voight, Carmen Ejogo, Ron Perlman, Colin Farrell and Johnny Depp in supporting roles. It is the first installment in the Fantastic Beasts film series, and ninth overall in the Wizarding World franchise, that began with the Harry Potter films.\\nQuestion: is fantastic beasts and where to find them a prequel?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 15/327 [00:13<04:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: The Vampire Diaries (season 8) -- The Vampire Diaries, an American supernatural drama, was renewed for an eighth season by The CW on March 11, 2016. On July 23, 2016, the CW announced that the upcoming season would be the series' last and would consist of 16 episodes. The season premiered on October 21, 2016 and concluded on March 10, 2017.\\nQuestion: will there be a season 8 of vampire diaries?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 16/327 [00:14<03:54,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: The Strangers (2008 film) -- The Strangers is a 2008 American slasher film written and directed by Bryan Bertino. Kristen (Liv Tyler) and James (Scott Speedman) are expecting a relaxing weekend at a family vacation home, but their stay turns out to be anything but peaceful as three masked torturers leave Kristen and James struggling for survival. Writer-director Bertino was inspired by real-life events: the Manson family Tate murders, a multiple homicide; the Keddie Cabin Murders, that occurred in California in 1981; and a series of break-ins that occurred in his own neighborhood as a child. Made on a budget of $9 million, the film was shot on location in rural South Carolina in the fall of 2006.\\nQuestion: was the movie strangers based on a true story?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/327 [00:14<03:52,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: Russell Group -- In March 2012 it was announced that four universities -- Durham, Exeter, Queen Mary University of London; and York -- would become members of the Russell Group in August of the same year. All of the new members had previously been members of the 1994 Group of British universities.\\nQuestion: is durham university part of the russell group?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/327 [00:15<04:18,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXAM\\n1. Answer by yes or no.\\n\\nDocument: The Resident (TV series) -- The Resident is an American medical drama television series aired by Fox Broadcasting Company that premiered on January 21, 2018, as a mid-season replacement entry in the 2017--18 television season. The fictional series focuses on the lives and duties of staff members at Chastain Park Memorial Hospital, while delving into the bureaucratic practices of the hospital industry. Formerly called The City, the show was purchased by Fox from Showtime in 2017. It was created by created by Amy Holden Jones, Hayley Schore, and Roshan Sethi. On May 10, 2017, Fox ordered a full 14-episode season and renewed the series for a second season on May 7, 2018. The first season officially concluded on May 14, 2018.\\nQuestion: is the tv show the resident over for the season?', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/327 [00:16<03:59,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Magnesium citrate -- Magnesium citrate is a magnesium preparation in salt form with citric acid in a 1:1 ratio (1 magnesium atom per citrate molecule). The name ``magnesium citrate'' is ambiguous and sometimes may refer to other salts such as trimagnesium citrate which has a magnesium:citrate ratio of 3:2.\\nQuestion: does magnesium citrate have citric acid in it?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 20/327 [00:16<03:34,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Post-office box -- Street Addressing will have the same street address of the post office, plus a ``unit number'' that matches the P.O. Box number. As an example, in El Centro, California, the post office is located at 1598 Main Street. Therefore, for P.O. Box 9975 (fictitious), the Street Addressing would be: 1598 Main Street Unit 9975, El Centro, CA. Nationally, the first five digits of the zip code may or may not be the same as the P.O. Box address, and the last four digits (Zip + 4) are virtually always different. Except for a few of the largest post offices in the U.S., the 'Street Addressing' (not the P.O. Box address) nine digit Zip + 4 is the same for all boxes at a given location.\\nQuestion: does p o box come before street address?\", 'No']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 21/327 [00:17<03:49,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"EXAM\\n1. Answer by yes or no.\\n\\nDocument: Spark plug -- A spark plug (sometimes, in British English, a sparking plug, and, colloquially, a plug) is a device for delivering electric current from an ignition system to the combustion chamber of a spark-ignition engine to ignite the compressed fuel/air mixture by an electric spark, while containing combustion pressure within the engine. A spark plug has a metal threaded shell, electrically isolated from a central electrode by a porcelain insulator. The central electrode, which may contain a resistor, is connected by a heavily insulated wire to the output terminal of an ignition coil or magneto. The spark plug's metal shell is screwed into the engine's cylinder head and thus electrically grounded. The central electrode protrudes through the porcelain insulator into the combustion chamber, forming one or more spark gaps between the inner end of the central electrode and usually one or more protuberances or structures attached to the inner end of the threaded shell and designated the side, earth, or ground electrode(s).\\nQuestion: does a spark plug keep an engine running?\", 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 21/327 [00:19<04:38,  1.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(model_input_string)\n\u001b[1;32m     10\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(model_input_string,padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs\u001b[39m.\u001b[39;49mto(model\u001b[39m.\u001b[39;49mdevice))\n\u001b[1;32m     12\u001b[0m response_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(outputs[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     13\u001b[0m predictions\u001b[39m.\u001b[39mappend(response_text)\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/generation_utils.py:1278\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1274\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[1;32m   1277\u001b[0m     \u001b[39m# 10. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1279\u001b[0m         input_ids,\n\u001b[1;32m   1280\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1281\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1282\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1283\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1284\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1285\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1286\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1287\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1288\u001b[0m     )\n\u001b[1;32m   1290\u001b[0m \u001b[39melif\u001b[39;00m is_sample_gen_mode:\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1293\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1294\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1299\u001b[0m     )\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/generation_utils.py:1672\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1669\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   1671\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 1672\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   1673\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   1674\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1675\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1676\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1677\u001b[0m )\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   1680\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1640\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1637\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1639\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1640\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1641\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1642\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1643\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1644\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1645\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1646\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1647\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1648\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1649\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1650\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1651\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1652\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1653\u001b[0m )\n\u001b[1;32m   1655\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1657\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1035\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1023\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1024\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1034\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1035\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1036\u001b[0m         hidden_states,\n\u001b[1;32m   1037\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1038\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1039\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1040\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1041\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1042\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1043\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1044\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1045\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1046\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:722\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    719\u001b[0m     attention_outputs \u001b[39m=\u001b[39m attention_outputs \u001b[39m+\u001b[39m cross_attention_outputs[\u001b[39m2\u001b[39m:]\n\u001b[1;32m    721\u001b[0m \u001b[39m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m](hidden_states)\n\u001b[1;32m    724\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39mif\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16 \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39misinf(hidden_states)\u001b[39m.\u001b[39many():\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:330\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m    329\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 330\u001b[0m     forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDenseReluDense(forwarded_states)\n\u001b[1;32m    331\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    332\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:306\u001b[0m, in \u001b[0;36mT5DenseGatedGeluDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m    305\u001b[0m     hidden_gelu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgelu_act(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwi_0(hidden_states))\n\u001b[0;32m--> 306\u001b[0m     hidden_linear \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwi_1(hidden_states)\n\u001b[1;32m    307\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_gelu \u001b[39m*\u001b[39m hidden_linear\n\u001b[1;32m    308\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/L2L_MLPrague23/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "references = [x==1 for x in dataset[\"label\"]]\n",
    "\n",
    "# Get predictions\n",
    "for item in tqdm(dataset):\n",
    "    model_input_string = prompt.apply(item)\n",
    "    inputs = tokenizer(model_input_string,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs.to(model.device))\n",
    "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    predictions.append(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using 'mt5' classifier; accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "correct_predictions = sum([pred == str(true) for pred, true in zip(predictions, references)])\n",
    "incorrect_predictions = sum([pred != str(true) for pred, true in zip(predictions, references)])\n",
    "\n",
    "accuracy = correct_predictions / (correct_predictions+incorrect_predictions)\n",
    "print(\"Prediction using '%s' classifier; accuracy: %s\" % (model.config.model_type, accuracy))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ✋ Hands on: Creation of an evaluation dataset \n",
    "\n",
    "* Download an existing dataset and transform it into a prompt input - label pair (either by creating your own prompt or by using the promtsource library).\n",
    "  * Text classification (https://huggingface.co/datasets/imdb)\n",
    "  * Named Entity Recognition (https://huggingface.co/datasets/polyglot_ner/viewer/en/train)\n",
    "  * Question Answering (https://huggingface.co/datasets/squad_v2)\n",
    "  * or other\n",
    "\n",
    "* Adjust the evaluation script accordingly\n",
    "\n",
    "* Create a function which will generate a few-shot (the prompt will include few demonstrations of the same task) prompt and label pairs.\n",
    "\n",
    "* evaluate some existing ICL models on your dataset (try both zero-shot and few-shot prompts):\n",
    "\n",
    "  * https://huggingface.co/google/flan-t5-large\n",
    "  * https://huggingface.co/allenai/mtk-instruct-3b-def-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_demonstrations():\n",
    "    # From your custom dataset pick random demostrations (prompt-label pairs)\n",
    "    pass\n",
    "\n",
    "def create_few_shot_prompt():\n",
    "    # With the pick_random_demonstrations() function create a new prompt\n",
    "    pass\n",
    "\n",
    "# Get models predictions\n",
    "\n",
    "# Evaluate (depending on your dataset you may need to change the evaluation script) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
