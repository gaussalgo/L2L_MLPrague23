{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-context learning (ICL)\n",
    "\n",
    "In context learning is a use of a generative model, where the description of a desired task is a part of the input. \n",
    "\n",
    "While pre-training, the model is trained on a task of \"guessing\" the right word in context. This is achieved by tasks like Masked Language Modeling (MLM) or Causal Language Modeling (CLM). During these tasks, the model aquires an inherent understanding of the language. \n",
    "\n",
    "After pre-training, traditionaly, we would then fine-tune the model through Supervised ML for a specific task for which we need:\n",
    "* Training data (input and label pairs)\n",
    "* Adding a specific layer (\"head\") to the model relevant to our desired task\n",
    "The resulting model is fit for that one specific task.\n",
    "\n",
    "When we talk about ICL, we mean models, which were finetuned using text inputs containing description of desired task(=prompts) and text outputs from several tasks.\n",
    "\n",
    "During inference of these models we provide the prompt. Being trained on a variety of prompts for multiple tasks, the model has a better understanding of the description of the task itself and thus may show ICL capability even on never before seen tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    " \n",
    "model_path = \"gaussalgo/mt5-base-priming-QA_en-cs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola/L2L_MLPrague23/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a young Swedish drama student named Lena']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is meant by: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\"\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs.to(model.device))\n",
    "outputs_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# predictions:\n",
    "outputs_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot vs few-shot\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model might understand the task from the input, but it does not know how do we expect it to respond. Therefore, if we have the model adjusted for such use, we can show it the format of the task from a few input-output examples and see if it comprehends.\n",
    "\n",
    "This approach is called in-context few-shot learning: In addition to the description of the task, we give the model a few input-output examples (demonstrations). Given these, the model has much easier time understanding the format of the interaction that we expect from it. The demonstration are the only lead the model has to understand the task at hand. We can see, that if we pick only examples with a negative sentiment, the model is unable to pick the correct label. \n",
    "\n",
    "In this setting, we need to standardize the format of prediction, so that the model can rely on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'positive or negative', 'positive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "input_zero_shot = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "input_few_shot_not_heterogenic = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: He said, that the consert was very dull.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: She came from school sad and lonely.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "input_few_shot = \"\"\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: He said, that the consert was very dull.\n",
    "Answer:\"negative\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: She came from school smiling and singing.\n",
    "Answer:\"positive\"\n",
    "Question: What is the sentiment of the context: positive or negative? \n",
    "Context: I am very happy to be here today.\n",
    "Answer:\"\"\n",
    "\"\"\"\n",
    "inputs = tokenizer([input_zero_shot,input_few_shot_not_heterogenic,  input_few_shot], return_tensors=\"pt\", padding=True)\n",
    "outputs = model.generate(**inputs.to(model.device))\n",
    "outputs_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# predictions:\n",
    "outputs_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should the prompts look like?\n",
    "For training a custom in-context learner we need text pairs of a prompt and label. While in the above example we see a unified prompt, in training it is beneficial to create multiple prompts for one task, as we want to support the models capability to understand the task by its description, not by identifying a task by a template. This diversivication should yield a benefit of having the model understanding never before seen tasks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Prompt source library...how to use existing prompts from promt source for your custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO evaluation script\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hands on] Creation of evaluation dataset \n",
    "\n",
    "Download an existing dataset and transform it into a prompt input - label pair.\n",
    "* Text classification (https://huggingface.co/datasets/imdb)\n",
    "* Named Entity Recognition (https://huggingface.co/datasets/polyglot_ner/viewer/en/train)\n",
    "* Question Answering (https://huggingface.co/datasets/squad_v2)\n",
    "* or other\n",
    "\n",
    "With the prompt source library create an evaluation dataset and adjust the evaluation script. \n",
    "\n",
    "Create a function which will generate a few-shot (the prompt will include few demonstrations of the same task) prompt and label pairs. Evaluate the model on your custom dataset\n",
    "\n",
    "Then evaluate some existing models:\n",
    "\n",
    "* https://huggingface.co/google/flan-t5-large\n",
    "* https://huggingface.co/allenai/mtk-instruct-3b-def-pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing models\n",
    "\n",
    "* T5 models (https://huggingface.co/t5-large) - pre-trained on mixture of tasks in text2text format\n",
    "* FLAN - T5 models (https://huggingface.co/google/flan-t5-large) - fine-tuned T5 model on 1000 additional tasks\n",
    "* mT5 models (https://huggingface.co/google/mt5-large) - pre-trained on 101 languages, no supervised tasks - needs to be fine-tuned\n",
    "* Tk models (https://huggingface.co/allenai/tk-instruct-large-def-pos) - fine-tuned T5 on tasks with prompts written as in-context instructions\n",
    "* mTk models (https://huggingface.co/allenai/mtk-instruct-3b-def-pos) - multilingual version of the Tk model\n",
    "* MPT (https://huggingface.co/mosaicml/mpt-7b)\n",
    "* Alpaca (https://github.com/tatsu-lab/stanford_alpaca)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
